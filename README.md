# 4D Scene Reconstruction using Casual Capturing Monocular Camera

## Overview
This Capstone Project, led by Asrar Alruwayqi under the guidance of Prof. Shubham Tulsiani, explores innovative methods for 4D scene reconstruction using a casual capturing monocular camera. The goal is to develop a system capable of reconstructing dynamic 3D scenes over time (4D) using simple, everyday equipment.

## Background
Traditional methods for 4D scene reconstruction often require specialized equipment, controlled environments, or multiple cameras, which can be costly and complex. This project seeks to simplify the process, enabling dynamic scene capture in natural, uncontrolled settings with a single camera.

## Project Objectives
- **Hybrid Scene Representation:** Utilize a tri-plane and deformation field hybrid approach to represent dynamic scenes.
- **Coarse-to-Fine Reconstruction:** Implement a coarse-to-fine strategy to ensure high-quality reconstruction.
- **Novel Dynamic View Prediction:** Employ video diffusion models to predict novel dynamic views from captured data.

## Methodology
1. **Tri-plane Representation using Multiview Synthetic Data:**


2. **Casual Capturing with a Monocular Camera on Real Data:**

## Installation
soon
## References
- Dynamic Novel-View Synthesis: A Reality Check
- D-NeRF: Neural Radiance Fields for Dynamic Scenes
- HexPlane: A Fast Representation for Dynamic Scenes.
- Nerfies: Deformable Neural Radiance Fields.
- NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis.
- TensoRF Tensorial Radiance Fields.
